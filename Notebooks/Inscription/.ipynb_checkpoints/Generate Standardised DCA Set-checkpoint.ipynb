{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5cf68cf",
   "metadata": {},
   "source": [
    "# Generate Standardised DCA Dataset\n",
    "\n",
    "This notebook runs through the entire train_balanced dataset and applies a dca of a single size across all images in the dataset. Any image with an exceedingly large DCA will be reduced before applying the erosion techniques to it.\n",
    "\n",
    "The dca masks used for augmentation are those extracted from the last project. \n",
    "\n",
    "\n",
    "## TO DO\n",
    "Make sure all .csv files are read and are contributing to the check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd6a05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append custom system path for custom modules folder in directory if not already\n",
    "import sys\n",
    "if  '../../Modules' not in sys.path:\n",
    "    sys.path.insert(0, '../../Modules')\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import isic_data as isic\n",
    "import os, os.path\n",
    "import shutil\n",
    "import random\n",
    "import realistic_dca as aug\n",
    "from dca_removal import reduce_intensity\n",
    "\n",
    "random.seed(72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74015c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "X = isic.get_data(type = 'none')\n",
    "\n",
    "lesions_train = X[0]\n",
    "lesions_test = X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8553c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the training melanoma masks\n",
    "t_mel_csv = pd.read_csv(r\"../../Data/Annotations/train_mel.csv\")\n",
    "t_oth_csv = pd.read_csv(r\"../../Data/Annotations/train_oth.csv\")\n",
    "# Load in the training melanoma intensity annotations\n",
    "dca_t_mel_csv = pd.read_csv(r\"../../Data/Annotations/dca_intensities_train_mel.csv\")\n",
    "dca_t_oth_csv = pd.read_csv(r\"../../Data/Annotations/dca_intensities_train_oth.csv\")\n",
    "\n",
    "# Segregate each mask type and retain the old index\n",
    "#small_dca_masks = dca_t_mel_csv.loc[dca_t_mel_csv['Small_DCA'] == 1].reset_index(drop = False)\n",
    "medium_dca_masks = dca_t_mel_csv.loc[dca_t_mel_csv['Medium_DCA'] == 1].reset_index(drop = False)\n",
    "large_dca_masks = dca_t_mel_csv.loc[dca_t_mel_csv['Large_DCA'] == 1].reset_index(drop = False)\n",
    "#oth_dca_masks = dca_t_mel_csv.loc[dca_t_mel_csv['Oth'] == 1].reset_index(drop = False)\n",
    "#tosmall_dca_masks = dca_t_oth_csv.loc[dca_t_oth_csv['Small_DCA'] == 1].reset_index(drop = False)\n",
    "tomedium_dca_masks = dca_t_oth_csv.loc[dca_t_oth_csv['Medium_DCA'] == 1].reset_index(drop = False)\n",
    "tolarge_dca_masks = dca_t_oth_csv.loc[dca_t_oth_csv['Large_DCA'] == 1].reset_index(drop = False)\n",
    "#tooth_dca_masks = dca_t_oth_csv.loc[dca_t_oth_csv['Oth'] == 1].reset_index(drop = False)\n",
    "\n",
    "# Append the original image name to the dataframe\n",
    "#small_dca_masks['Original_Image_Name'] = [small_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(small_dca_masks.index))]\n",
    "medium_dca_masks['Original_Image_Name'] = [medium_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(medium_dca_masks.index))]\n",
    "large_dca_masks['Original_Image_Name'] = [large_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(large_dca_masks.index))]\n",
    "#oth_dca_masks['Original_Image_Name'] = [oth_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(oth_dca_masks.index))]\n",
    "#tosmall_dca_masks['Original_Image_Name'] = [tosmall_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(tosmall_dca_masks.index))]\n",
    "tomedium_dca_masks['Original_Image_Name'] = [tomedium_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(tomedium_dca_masks.index))]\n",
    "tolarge_dca_masks['Original_Image_Name'] = [tolarge_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(tolarge_dca_masks.index))]\n",
    "#tooth_dca_masks['Original_Image_Name'] = [tooth_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(tooth_dca_masks.index))]\n",
    "\n",
    "#small_dca_masks = list(small_dca_masks['Image_Name']) + list(tosmall_dca_masks['Image_Name'])\n",
    "medium_dca_masks = list(medium_dca_masks['Image_Name']) + list(tomedium_dca_masks['Image_Name'])\n",
    "large_dca_masks = list(large_dca_masks['Image_Name']) + list(tolarge_dca_masks['Image_Name'])\n",
    "#oth_dca_masks = list(oth_dca_masks['Image_Name']) +  list(tooth_dca_masks['Image_Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c208cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the training melanoma masks\n",
    "v_mel_csv = pd.read_csv(r\"../../Data/Annotations/val_mel.csv\")\n",
    "v_oth_csv = pd.read_csv(r\"../../Data/Annotations/val_oth.csv\")\n",
    "# Load in the training melanoma intensity annotations\n",
    "dca_v_mel_csv = pd.read_csv(r\"../../Data/Annotations/dca_intensities_val_mel.csv\")\n",
    "dca_v_oth_csv = pd.read_csv(r\"../../Data/Annotations/dca_intensities_val_oth.csv\")\n",
    "\n",
    "# Segregate each mask type and retain the old index\n",
    "#vsmall_dca_masks = dca_v_mel_csv.loc[dca_v_mel_csv['Small_DCA'] == 1].reset_index(drop = False)\n",
    "vmedium_dca_masks = dca_v_mel_csv.loc[dca_v_mel_csv['Medium_DCA'] == 1].reset_index(drop = False)\n",
    "vlarge_dca_masks = dca_v_mel_csv.loc[dca_v_mel_csv['Large_DCA'] == 1].reset_index(drop = False)\n",
    "#voth_dca_masks = dca_v_mel_csv.loc[dca_v_mel_csv['Oth'] == 1].reset_index(drop = False)\n",
    "#vosmall_dca_masks = dca_v_oth_csv.loc[dca_v_oth_csv['Small_DCA'] == 1].reset_index(drop = False)\n",
    "vomedium_dca_masks = dca_v_oth_csv.loc[dca_v_oth_csv['Medium_DCA'] == 1].reset_index(drop = False)\n",
    "volarge_dca_masks = dca_v_oth_csv.loc[dca_v_oth_csv['Large_DCA'] == 1].reset_index(drop = False)\n",
    "#vooth_dca_masks = dca_v_oth_csv.loc[dca_v_oth_csv['Oth'] == 1].reset_index(drop = False)\n",
    "\n",
    "# Append the original image name to the dataframe\n",
    "#vsmall_dca_masks['Original_Image_Name'] = [vsmall_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(vsmall_dca_masks.index))]\n",
    "vmedium_dca_masks['Original_Image_Name'] = [vmedium_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(vmedium_dca_masks.index))]\n",
    "vlarge_dca_masks['Original_Image_Name'] = [vlarge_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(vlarge_dca_masks.index))]\n",
    "#voth_dca_masks['Original_Image_Name'] = [voth_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(oth_dca_masks.index))]\n",
    "#vosmall_dca_masks['Original_Image_Name'] = [vosmall_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(vosmall_dca_masks.index))]\n",
    "vomedium_dca_masks['Original_Image_Name'] = [vomedium_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(vomedium_dca_masks.index))]\n",
    "volarge_dca_masks['Original_Image_Name'] = [volarge_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(volarge_dca_masks.index))]\n",
    "#vooth_dca_masks['Original_Image_Name'] = [vooth_dca_masks['Image_Name'][i][:-9] + '.jpg' for i in range(len(vooth_dca_masks.index))]\n",
    "\n",
    "#vsmall_dca_masks = list(vsmall_dca_masks['Image_Name']) + list(vosmall_dca_masks['Image_Name'])\n",
    "vmedium_dca_masks = list(vmedium_dca_masks['Image_Name']) + list(vomedium_dca_masks['Image_Name'])\n",
    "vlarge_dca_masks = list(vlarge_dca_masks['Image_Name']) + list(volarge_dca_masks['Image_Name'])\n",
    "#voth_dca_masks = list(voth_dca_masks['Image_Name']) + list(vooth_dca_masks['Image_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b29c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check savepath exists..\n",
    "savepath = r\"../../Data/train_balanced_augmented_std_224x224\"\n",
    "\n",
    "# if it does then delete it and recreate it\n",
    "if os.path.exists(savepath):\n",
    "    shutil.rmtree(savepath)\n",
    "os.mkdir(savepath)\n",
    "os.mkdir(savepath + r\"/train\")\n",
    "os.mkdir(savepath + r\"/val\")\n",
    "os.mkdir(savepath + r\"/train/mel\")\n",
    "os.mkdir(savepath + r\"/val/mel\")\n",
    "os.mkdir(savepath + r\"/train/oth\")\n",
    "os.mkdir(savepath + r\"/val/oth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d36bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all of the images in the dataset, \n",
    "# when the image has a medium or large DCA in it, attempt to reduce its intensity. \n",
    "        # when its size hasnt changed, apply the standardised DCA.\n",
    "        # otherwise, bump image size back to 224x224 and then apply standardised DCA (maybe change to the other augmentation here)\n",
    "# when the image has no dca, just ust the standardised DCA method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1863aae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ISIC2017_0001133_mel_MASK.png'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_dca_masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0424387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAINING SET\n",
    "mask_path_mel = r\"../../Data/DCA_Masks/train/mel/\"\n",
    "mask_path_oth = r\"../../Data/DCA_Masks/train/oth/\"\n",
    "for i, img in enumerate(lesions_train.images):\n",
    "    temp_str = lesions_train.filenames[i][:-4] + \"_MASK.png\"\n",
    "    #print(temp_str)\n",
    "    if (temp_str in medium_dca_masks) or (temp_str in large_dca_masks):\n",
    "        # load in the original mask\n",
    "        if temp_str[-12:-9] == \"mel\":\n",
    "            mask = cv2.imread(mask_path_mel + temp_str)\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            mask = cv2.imread(mask_path_oth + temp_str)\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # reduce its intensity\n",
    "        cimg, cmask = reduce_intensity(img, mask)\n",
    "        \n",
    "        # bump up size\n",
    "        cimg = cv2.resize(cimg, dsize = (224,224), interpolation = cv2.INTER_CUBIC)\n",
    "        cmask = cv2.resize(cmask, dsize = (224,224), interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        # pass to DCA blur method - NON-STANDARDISED MUST MATCH DCA ALREADY IN IMAGE\n",
    "        result = aug.augment_dca(cimg, cmask, blur_type = \"erode\")\n",
    "        \n",
    "        # save the result to appropriate directory\n",
    "        result = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "        dest = lesions_train.filenames[i][-7:-4]\n",
    "        savepath = r\"../../Data/train_balanced_augmented_std_224x224/train/\" + dest + r\"/\" + lesions_train.filenames[i][:-4] + \".png\"\n",
    "        cv2.imwrite(savepath, result)\n",
    "    else:\n",
    "        # pass to DCA blur method - STANDARDISED\n",
    "        result = aug.augment_standardised_dca(img, blur_type = \"erode\")\n",
    "\n",
    "        # save the result to appropriate directory\n",
    "        result = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "        dest = lesions_train.filenames[i][-7:-4]\n",
    "        #print(temp_str)\n",
    "        savepath = r\"../../Data/train_balanced_augmented_std_224x224/train/\" + dest + r\"/\" + lesions_train.filenames[i][:-4] + \".png\"\n",
    "        cv2.imwrite(savepath, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12512d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VALIDATION SET\n",
    "mask_path_mel = r\"../../Data/DCA_Masks/val/mel/\"\n",
    "mask_path_oth = r\"../../Data/DCA_Masks/val/oth/\"\n",
    "\n",
    "for i, img in enumerate(lesions_test.images):\n",
    "    temp_str = lesions_test.filenames[i][:-4] + \"_MASK.png\"\n",
    "    if (temp_str in vmedium_dca_masks) or (temp_str in vlarge_dca_masks):\n",
    "        # load in the original mask\n",
    "        if temp_str[-12:-9] == \"mel\":\n",
    "            mask = cv2.imread(mask_path_mel + temp_str)\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            mask = cv2.imread(mask_path_oth + temp_str)\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # reduce its intensity\n",
    "        cimg, cmask = reduce_intensity(img, mask)\n",
    "        \n",
    "        # bump up size\n",
    "        cimg = cv2.resize(cimg, dsize = (224,224), interpolation = cv2.INTER_CUBIC)\n",
    "        cmask = cv2.resize(cmask, dsize = (224,224), interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        # pass to DCA blur method - NON-STANDARDISED MUST MATCH DCA ALREADY IN IMAGE\n",
    "        result = aug.augment_dca(cimg, cmask, blur_type = \"erode\")\n",
    "        \n",
    "        # save the result to appropriate directory\n",
    "        result = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "        dest = lesions_train.filenames[i][-7:-4]\n",
    "        savepath = r\"../../Data/train_balanced_augmented_std_224x224/val/\" + dest + r\"/\" + lesions_train.filenames[i][:-4] + \".png\"\n",
    "        cv2.imwrite(savepath, result)\n",
    "    else:\n",
    "        # pass to DCA blur method - STANDARDISED\n",
    "        result = aug.augment_standardised_dca(img, blur_type = \"erode\")\n",
    "\n",
    "        # save the result to appropriate directory\n",
    "        result = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "        dest = lesions_train.filenames[i][-7:-4]\n",
    "        savepath = r\"../../Data/train_balanced_augmented_std_224x224/val/\" + dest + r\"/\" + lesions_train.filenames[i][:-4] + \".png\"\n",
    "        cv2.imwrite(savepath, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c3e92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a62fa110",
   "metadata": {},
   "source": [
    "## TEST AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d26c5fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIC2020_4658487_oth_MASK.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_name = \"ISIC2020_4658487_oth.jpg\"\n",
    "test_temp_str = test_img_name[:-4] + \"_MASK.png\"\n",
    "\n",
    "print(test_temp_str)\n",
    "\n",
    "test_temp_str in vmedium_dca_masks or test_temp_str in vlarge_dca_masks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
